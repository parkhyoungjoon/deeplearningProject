{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = pd.read_csv('./DATA/MBTI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBTI 유형을 숫자로 변환하는 딕셔너리 생성\n",
    "labels = dict(zip(dataDF['type'].unique().tolist(), range(16)))\n",
    "dataDF['type'] = dataDF['type'].map(lambda x: labels[x])\n",
    "\n",
    "# 각 MBTI 유형의 빈도를 계산하고 딕셔너리로 변환\n",
    "sample_dict = {i:5000 for i in range(16)}\n",
    "\n",
    "# SMOTE 설정\n",
    "smote = SMOTE(random_state=42, sampling_strategy=sample_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000, min_df=3)\n",
    "X_tfidf = vectorizer.fit(dataDF['posts'].to_numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 비율 유지하여 샘플링\n",
    "sampled_indices=[]\n",
    "re_sample_df = pd.DataFrame(columns=['posts','type']).reset_index()\n",
    "num_samples = dataDF.shape[0]//12  # 전체 샘플 수\n",
    "sampled_df = dataDF[~dataDF.index.isin(sampled_indices)].groupby('type', group_keys=False).apply(lambda x: x.sample(frac=num_samples / len(dataDF), random_state=42, replace=False))\n",
    "sampled_indices.extend(sampled_df.index)\n",
    "targetDF = sampled_df[['type']]\n",
    "featureDF = sampled_df.drop(columns='type')\n",
    "featureDF = X_tfidf.transform(featureDF.to_numpy().reshape(-1)).toarray()\n",
    "X_resampled, y_resampled = smote.fit_resample(featureDF, targetDF)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df_tfidf = pd.DataFrame(X_resampled, columns=feature_names)\n",
    "lists = []\n",
    "for index, row in df_tfidf.iterrows():\n",
    "    highest_tfidf = row.nlargest(500)  # 상위 3개 단어\n",
    "    words = ''\n",
    "    for word, value in highest_tfidf.items():\n",
    "        words = words + ' ' + word\n",
    "    lists.append(words)\n",
    "X_resampled_df = pd.DataFrame(lists,columns=['posts'])\n",
    "y_resampled_df = pd.DataFrame(y_resampled.values, columns=['type'])\n",
    "resampled_df = pd.concat([X_resampled_df, y_resampled_df], axis=1)\n",
    "re_sample_df = pd.concat([re_sample_df,resampled_df])\n",
    "re_sample_df = re_sample_df.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_labels = {value: key for key, value in labels.items()}\n",
    "re_sample_df['type'] = re_sample_df['type'].map(lambda x:r_labels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_sample_df.to_csv('mbti_sample.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INTJ': 0,\n",
       " 'INTP': 1,\n",
       " 'ISFJ': 2,\n",
       " 'ISFP': 3,\n",
       " 'ISTJ': 4,\n",
       " 'ISTP': 5,\n",
       " 'ENFJ': 6,\n",
       " 'ENFP': 7,\n",
       " 'ENTJ': 8,\n",
       " 'ENTP': 9,\n",
       " 'ESFJ': 10,\n",
       " 'ESFP': 11,\n",
       " 'ESTJ': 12,\n",
       " 'ESTP': 13,\n",
       " 'INFJ': 14,\n",
       " 'INFP': 15}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re_sample_df['type'].map()\n",
    "labels.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF['type'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDF = dataDF.drop(columns='type')\n",
    "featureDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.DF_duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_sample_df = pd.DataFrame(columns=['posts','type']).reset_index()\n",
    "re_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.DF_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.target_select('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dataDF['type'] == 0\n",
    "type_one_rows = dataDF[mask]\n",
    "\n",
    "# 랜덤으로 절반 선택하여 삭제\n",
    "rows_to_drop = type_one_rows.sample(frac=0.4, random_state=42).index\n",
    "\n",
    "# 데이터프레임에서 해당 행 삭제\n",
    "dataDF = dataDF.drop(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42,sampling_strategy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDF = dataDF['type']\n",
    "featureDF = dataDF['posts']\n",
    "X_resampled, y_resampled = smote.fit_resample(featureDF, targetDF)\n",
    "df_tfidf = pd.DataFrame([featureDF,targetDF]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000,min_df=3)\n",
    "X_tfidf = vectorizer.fit(dataDF['posts'].to_numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 비율 유지하여 샘플링\n",
    "sampled_indices = []\n",
    "\n",
    "for i in range(4):\n",
    "    num_samples = dataDF.shape[0]//10  # 전체 샘플 수\n",
    "    # sampled_df = dataDF.groupby('type', group_keys=False).apply(lambda x: x.sample(frac=num_samples/len(dataDF), random_state=random.randint(1,42)))\n",
    "    sampled_df = dataDF[~dataDF.index.isin(sampled_indices)].groupby('type', group_keys=False).apply(lambda x: x.sample(frac=num_samples / len(dataDF), random_state=42, replace=False))\n",
    "    sampled_indices.extend(sampled_df.index)\n",
    "    targetDF = sampled_df[['type']]\n",
    "    featureDF = sampled_df.drop(columns='type')\n",
    "    featureDF = X_tfidf.transform(featureDF.to_numpy().reshape(-1)).toarray()\n",
    "    X_resampled, y_resampled = smote.fit_resample(featureDF, targetDF)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    df_tfidf = pd.DataFrame(X_resampled[y_resampled[y_resampled['type'] == 0].index], columns=feature_names)\n",
    "    lists = []\n",
    "    for index, row in df_tfidf.iterrows():\n",
    "        highest_tfidf = row.nlargest(500)  # 상위 3개 단어\n",
    "        words = ''\n",
    "        for word, value in highest_tfidf.items():\n",
    "            words = words + ' ' + word\n",
    "        lists.append(words)\n",
    "    smoteDF = pd.DataFrame(lists,columns=['posts'])\n",
    "    smoteDF['type']= 0\n",
    "    smoteDF\n",
    "    dataDF = pd.concat([dataDF,smoteDF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_labels = {value: key for key, value in labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF['type'] = dataDF['type'].map(lambda x:r_labels[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF['type'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF.to_csv('./DATA/MBTI_smote.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
